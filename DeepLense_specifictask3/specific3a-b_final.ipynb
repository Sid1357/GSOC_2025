{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super-Resolution for Strong Lensing Images\n",
    "\n",
    "This notebook implements a deep learning-based super-resolution approach for strong lensing images. It is divided into two main tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task III.A: Super-Resolution on Simulated Data\n",
    "\n",
    "**Objective:**  \n",
    "Upscale low-resolution simulated strong lensing images using high-resolution samples as ground truths.\n",
    "\n",
    "**Dataset:**  \n",
    "- **Link:** [Task III.A](https://drive.google.com/file/d/1uJmDZw649XS-r-dYs9WD-OPwF_TIroVw/view?usp=sharing)\n",
    "\n",
    "**Implementation Steps:**\n",
    "1. **Data Loading and Preprocessing:**  \n",
    "   - Used a custom PyTorch `Dataset` class to load `.npy` files for HR and LR images.\n",
    "   - Created a 90:10 trainâ€“validation split.\n",
    "2. **Model Architecture:**  \n",
    "   - Implementd a baseline model (e.g., SRCNN) that first upsamples the LR image (using bilinear interpolation) and then refines it with convolutional layers.\n",
    "3. **Training Loop:**  \n",
    "   - Traind the model using MSE loss.\n",
    "   - Tracked training and validation metrics (MSE, PSNR, SSIM).\n",
    "   - Used early stopping and saved the best model.\n",
    "4. **Evaluation:**  \n",
    "   - Computed evaluation metrics on the validation set.\n",
    "   - Displayed sample outputs for qualitative evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-22T19:41:24.779174Z",
     "iopub.status.busy": "2025-03-22T19:41:24.778810Z",
     "iopub.status.idle": "2025-03-22T19:41:25.362885Z",
     "shell.execute_reply": "2025-03-22T19:41:25.361738Z",
     "shell.execute_reply.started": "2025-03-22T19:41:24.779146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skimage.metrics import peak_signal_noise_ratio, mean_squared_error, structural_similarity\n",
    "from tqdm import tqdm \n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:11:05.891160Z",
     "iopub.status.busy": "2025-03-22T19:11:05.890700Z",
     "iopub.status.idle": "2025-03-22T19:11:05.897857Z",
     "shell.execute_reply": "2025-03-22T19:11:05.897108Z",
     "shell.execute_reply.started": "2025-03-22T19:11:05.891128Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SuperResolutionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class for super-resolution tasks.\n",
    "    It expects two directories: one for high-resolution (HR) images and one for low-resolution (LR) images.\n",
    "    The images are stored as .npy files.\n",
    "    \"\"\"\n",
    "    def __init__(self, hr_dir, lr_dir, transform=None):\n",
    "        self.hr_dir = hr_dir\n",
    "        self.lr_dir = lr_dir\n",
    "        self.hr_files = sorted([os.path.join(hr_dir, f) for f in os.listdir(hr_dir) if f.endswith('.npy')])\n",
    "        self.lr_files = sorted([os.path.join(lr_dir, f) for f in os.listdir(lr_dir) if f.endswith('.npy')])\n",
    "        self.transform = transform\n",
    "\n",
    "        # Ensure both lists have the same length\n",
    "        assert len(self.hr_files) == len(self.lr_files), \"Mismatch between HR and LR files count!\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hr_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hr = np.load(self.hr_files[idx])\n",
    "        lr = np.load(self.lr_files[idx])\n",
    "        \n",
    "        # Convert to float32 and add channel dimension if needed\n",
    "        # (Assuming images are grayscale. Modify if they are multi-channel)\n",
    "        hr = hr.astype(np.float32)\n",
    "        lr = lr.astype(np.float32)\n",
    "        if hr.ndim == 2:\n",
    "            hr = hr[None, :, :]  # Add channel dimension\n",
    "        if lr.ndim == 2:\n",
    "            lr = lr[None, :, :]\n",
    "        \n",
    "        sample = {'lr': torch.from_numpy(lr), 'hr': torch.from_numpy(hr)}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:13:33.787586Z",
     "iopub.status.busy": "2025-03-22T19:13:33.787127Z",
     "iopub.status.idle": "2025-03-22T19:13:33.827508Z",
     "shell.execute_reply": "2025-03-22T19:13:33.826794Z",
     "shell.execute_reply.started": "2025-03-22T19:13:33.787560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "task3a_hr_dir = '/kaggle/input/task3a/Dataset/HR'\n",
    "task3a_lr_dir = '/kaggle/input/task3a/Dataset/LR'\n",
    "\n",
    "# Create the dataset instance (already tested earlier)\n",
    "dataset_task3a = SuperResolutionDataset(task3a_hr_dir, task3a_lr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:22:29.156409Z",
     "iopub.status.busy": "2025-03-22T19:22:29.156079Z",
     "iopub.status.idle": "2025-03-22T19:22:29.162249Z",
     "shell.execute_reply": "2025-03-22T19:22:29.161331Z",
     "shell.execute_reply.started": "2025-03-22T19:22:29.156382Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, num_channels=1):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=9, padding=4)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(32, num_channels, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:22:42.736699Z",
     "iopub.status.busy": "2025-03-22T19:22:42.736376Z",
     "iopub.status.idle": "2025-03-22T19:22:42.741424Z",
     "shell.execute_reply": "2025-03-22T19:22:42.740557Z",
     "shell.execute_reply.started": "2025-03-22T19:22:42.736673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SuperResolutionModel(nn.Module):\n",
    "    def __init__(self, scale_factor=2):\n",
    "        super(SuperResolutionModel, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.srcnn = SRCNN(num_channels=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Upsample LR image to HR size using bilinear interpolation\n",
    "        x_up = nn.functional.interpolate(x, scale_factor=self.scale_factor, mode='bilinear', align_corners=False)\n",
    "        out = self.srcnn(x_up)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:22:53.521994Z",
     "iopub.status.busy": "2025-03-22T19:22:53.521687Z",
     "iopub.status.idle": "2025-03-22T19:22:53.560094Z",
     "shell.execute_reply": "2025-03-22T19:22:53.559322Z",
     "shell.execute_reply.started": "2025-03-22T19:22:53.521970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "task3a_hr_dir = '/kaggle/input/task3a/Dataset/HR'\n",
    "task3a_lr_dir = '/kaggle/input/task3a/Dataset/LR'\n",
    "\n",
    "# Assume SuperResolutionDataset is already defined as in previous steps\n",
    "dataset_task3a = SuperResolutionDataset(task3a_hr_dir, task3a_lr_dir)\n",
    "train_size = int(0.9 * len(dataset_task3a))\n",
    "val_size = len(dataset_task3a) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset_task3a, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:23:04.895959Z",
     "iopub.status.busy": "2025-03-22T19:23:04.895651Z",
     "iopub.status.idle": "2025-03-22T19:23:04.902701Z",
     "shell.execute_reply": "2025-03-22T19:23:04.901959Z",
     "shell.execute_reply.started": "2025-03-22T19:23:04.895933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = SuperResolutionModel(scale_factor=2).cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:23:19.952208Z",
     "iopub.status.busy": "2025-03-22T19:23:19.951884Z",
     "iopub.status.idle": "2025-03-22T19:23:19.957922Z",
     "shell.execute_reply": "2025-03-22T19:23:19.956973Z",
     "shell.execute_reply.started": "2025-03-22T19:23:19.952182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stops the training if validation loss doesn't improve after a given patience.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss:\n",
    "            if self.verbose and self.best_loss is not None:\n",
    "                print(f\"Validation loss improved from {self.best_loss:.6f} to {val_loss:.6f}.\")\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"Validation loss did not improve. EarlyStopping counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:23:32.743963Z",
     "iopub.status.busy": "2025-03-22T19:23:32.743619Z",
     "iopub.status.idle": "2025-03-22T19:23:32.749988Z",
     "shell.execute_reply": "2025-03-22T19:23:32.749220Z",
     "shell.execute_reply.started": "2025-03-22T19:23:32.743935Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_mse = 0.0\n",
    "    total_psnr = 0.0\n",
    "    total_ssim = 0.0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            lr = batch['lr'].cuda()\n",
    "            hr = batch['hr'].cuda()\n",
    "            sr = model(lr)\n",
    "            for i in range(sr.size(0)):\n",
    "                sr_img = sr[i].cpu().numpy().squeeze()\n",
    "                hr_img = hr[i].cpu().numpy().squeeze()\n",
    "                mse_val = mean_squared_error(hr_img, sr_img)\n",
    "                psnr_val = peak_signal_noise_ratio(hr_img, sr_img, data_range=hr_img.max()-hr_img.min())\n",
    "                ssim_val = structural_similarity(hr_img, sr_img, data_range=hr_img.max()-hr_img.min())\n",
    "                total_mse += mse_val\n",
    "                total_psnr += psnr_val\n",
    "                total_ssim += ssim_val\n",
    "                count += 1\n",
    "    avg_mse = total_mse / count\n",
    "    avg_psnr = total_psnr / count\n",
    "    avg_ssim = total_ssim / count\n",
    "    return avg_mse, avg_psnr, avg_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:24:05.174176Z",
     "iopub.status.busy": "2025-03-22T19:24:05.173829Z",
     "iopub.status.idle": "2025-03-22T19:39:58.424584Z",
     "shell.execute_reply": "2025-03-22T19:39:58.423612Z",
     "shell.execute_reply.started": "2025-03-22T19:24:05.174148Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.000232 | Val Loss: 0.000079 | Val MSE: 0.000079 | PSNR: 41.04 | SSIM: 0.9694\n",
      "--> Best model saved at epoch 1 with validation loss: 0.000079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 0.000073 | Val Loss: 0.000069 | Val MSE: 0.000069 | PSNR: 41.65 | SSIM: 0.9732\n",
      "--> Best model saved at epoch 2 with validation loss: 0.000069\n",
      "Validation loss improved from 0.000079 to 0.000069.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 0.000068 | Val Loss: 0.000067 | Val MSE: 0.000067 | PSNR: 41.80 | SSIM: 0.9741\n",
      "--> Best model saved at epoch 3 with validation loss: 0.000067\n",
      "Validation loss improved from 0.000069 to 0.000067.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 0.000066 | Val Loss: 0.000066 | Val MSE: 0.000066 | PSNR: 41.87 | SSIM: 0.9746\n",
      "--> Best model saved at epoch 4 with validation loss: 0.000066\n",
      "Validation loss improved from 0.000067 to 0.000066.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 0.000065 | Val Loss: 0.000065 | Val MSE: 0.000065 | PSNR: 41.92 | SSIM: 0.9750\n",
      "--> Best model saved at epoch 5 with validation loss: 0.000065\n",
      "Validation loss improved from 0.000066 to 0.000065.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 0.000065 | Val Loss: 0.000064 | Val MSE: 0.000064 | PSNR: 41.95 | SSIM: 0.9752\n",
      "--> Best model saved at epoch 6 with validation loss: 0.000064\n",
      "Validation loss improved from 0.000065 to 0.000064.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Train Loss: 0.000064 | Val Loss: 0.000065 | Val MSE: 0.000065 | PSNR: 41.91 | SSIM: 0.9752\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 0.000064 | Val Loss: 0.000066 | Val MSE: 0.000066 | PSNR: 41.86 | SSIM: 0.9749\n",
      "Validation loss did not improve. EarlyStopping counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 0.000064 | Val Loss: 0.000063 | Val MSE: 0.000063 | PSNR: 42.02 | SSIM: 0.9756\n",
      "--> Best model saved at epoch 9 with validation loss: 0.000063\n",
      "Validation loss improved from 0.000064 to 0.000063.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 0.000064 | Val Loss: 0.000063 | Val MSE: 0.000063 | PSNR: 42.03 | SSIM: 0.9757\n",
      "--> Best model saved at epoch 10 with validation loss: 0.000063\n",
      "Validation loss improved from 0.000063 to 0.000063.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Train Loss: 0.000063 | Val Loss: 0.000063 | Val MSE: 0.000063 | PSNR: 42.06 | SSIM: 0.9758\n",
      "--> Best model saved at epoch 11 with validation loss: 0.000063\n",
      "Validation loss improved from 0.000063 to 0.000063.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | Train Loss: 0.000063 | Val Loss: 0.000063 | Val MSE: 0.000063 | PSNR: 42.07 | SSIM: 0.9759\n",
      "--> Best model saved at epoch 12 with validation loss: 0.000063\n",
      "Validation loss improved from 0.000063 to 0.000063.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | Train Loss: 0.000063 | Val Loss: 0.000063 | Val MSE: 0.000063 | PSNR: 42.08 | SSIM: 0.9760\n",
      "--> Best model saved at epoch 13 with validation loss: 0.000063\n",
      "Validation loss improved from 0.000063 to 0.000063.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | Train Loss: 0.000063 | Val Loss: 0.000063 | Val MSE: 0.000063 | PSNR: 42.02 | SSIM: 0.9756\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | Train Loss: 0.000063 | Val Loss: 0.000062 | Val MSE: 0.000062 | PSNR: 42.10 | SSIM: 0.9761\n",
      "--> Best model saved at epoch 15 with validation loss: 0.000062\n",
      "Validation loss improved from 0.000063 to 0.000062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | Train Loss: 0.000062 | Val Loss: 0.000062 | Val MSE: 0.000062 | PSNR: 42.11 | SSIM: 0.9762\n",
      "--> Best model saved at epoch 16 with validation loss: 0.000062\n",
      "Validation loss improved from 0.000062 to 0.000062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | Train Loss: 0.000062 | Val Loss: 0.000062 | Val MSE: 0.000062 | PSNR: 42.11 | SSIM: 0.9762\n",
      "--> Best model saved at epoch 17 with validation loss: 0.000062\n",
      "Validation loss improved from 0.000062 to 0.000062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | Train Loss: 0.000062 | Val Loss: 0.000062 | Val MSE: 0.000062 | PSNR: 42.12 | SSIM: 0.9762\n",
      "--> Best model saved at epoch 18 with validation loss: 0.000062\n",
      "Validation loss improved from 0.000062 to 0.000062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | Train Loss: 0.000062 | Val Loss: 0.000063 | Val MSE: 0.000063 | PSNR: 42.07 | SSIM: 0.9762\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | Train Loss: 0.000062 | Val Loss: 0.000062 | Val MSE: 0.000062 | PSNR: 42.12 | SSIM: 0.9762\n",
      "--> Best model saved at epoch 20 with validation loss: 0.000062\n",
      "Validation loss improved from 0.000062 to 0.000062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | Train Loss: 0.000062 | Val Loss: 0.000062 | Val MSE: 0.000062 | PSNR: 42.15 | SSIM: 0.9764\n",
      "--> Best model saved at epoch 21 with validation loss: 0.000062\n",
      "Validation loss improved from 0.000062 to 0.000062.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | Train Loss: 0.000062 | Val Loss: 0.000061 | Val MSE: 0.000061 | PSNR: 42.15 | SSIM: 0.9764\n",
      "--> Best model saved at epoch 22 with validation loss: 0.000061\n",
      "Validation loss improved from 0.000062 to 0.000061.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | Train Loss: 0.000062 | Val Loss: 0.000061 | Val MSE: 0.000061 | PSNR: 42.16 | SSIM: 0.9765\n",
      "--> Best model saved at epoch 23 with validation loss: 0.000061\n",
      "Validation loss improved from 0.000061 to 0.000061.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | Train Loss: 0.000062 | Val Loss: 0.000061 | Val MSE: 0.000061 | PSNR: 42.17 | SSIM: 0.9765\n",
      "--> Best model saved at epoch 24 with validation loss: 0.000061\n",
      "Validation loss improved from 0.000061 to 0.000061.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 | Train Loss: 0.000061 | Val Loss: 0.000061 | Val MSE: 0.000061 | PSNR: 42.17 | SSIM: 0.9766\n",
      "--> Best model saved at epoch 25 with validation loss: 0.000061\n",
      "Validation loss improved from 0.000061 to 0.000061.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 | Train Loss: 0.000061 | Val Loss: 0.000061 | Val MSE: 0.000061 | PSNR: 42.18 | SSIM: 0.9766\n",
      "--> Best model saved at epoch 26 with validation loss: 0.000061\n",
      "Validation loss improved from 0.000061 to 0.000061.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 | Train Loss: 0.000061 | Val Loss: 0.000062 | Val MSE: 0.000062 | PSNR: 42.13 | SSIM: 0.9763\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 | Train Loss: 0.000061 | Val Loss: 0.000061 | Val MSE: 0.000061 | PSNR: 42.20 | SSIM: 0.9767\n",
      "--> Best model saved at epoch 28 with validation loss: 0.000061\n",
      "Validation loss improved from 0.000061 to 0.000061.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 | Train Loss: 0.000061 | Val Loss: 0.000061 | Val MSE: 0.000061 | PSNR: 42.20 | SSIM: 0.9767\n",
      "--> Best model saved at epoch 29 with validation loss: 0.000061\n",
      "Validation loss improved from 0.000061 to 0.000061.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 | Train Loss: 0.000061 | Val Loss: 0.000061 | Val MSE: 0.000061 | PSNR: 42.21 | SSIM: 0.9767\n",
      "--> Best model saved at epoch 30 with validation loss: 0.000061\n",
      "Validation loss improved from 0.000061 to 0.000061.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 | Train Loss: 0.000061 | Val Loss: 0.000061 | Val MSE: 0.000061 | PSNR: 42.21 | SSIM: 0.9768\n",
      "--> Best model saved at epoch 31 with validation loss: 0.000061\n",
      "Validation loss improved from 0.000061 to 0.000061.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 | Train Loss: 0.000061 | Val Loss: 0.000062 | Val MSE: 0.000062 | PSNR: 42.14 | SSIM: 0.9764\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 | Train Loss: 0.000061 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.22 | SSIM: 0.9768\n",
      "--> Best model saved at epoch 33 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000061 to 0.000060.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 | Train Loss: 0.000061 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.23 | SSIM: 0.9768\n",
      "--> Best model saved at epoch 34 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000060 to 0.000060.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 | Train Loss: 0.000061 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.23 | SSIM: 0.9769\n",
      "--> Best model saved at epoch 35 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000060 to 0.000060.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 | Train Loss: 0.000061 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.23 | SSIM: 0.9769\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 | Train Loss: 0.000061 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.23 | SSIM: 0.9769\n",
      "--> Best model saved at epoch 37 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000060 to 0.000060.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 | Train Loss: 0.000061 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.24 | SSIM: 0.9769\n",
      "--> Best model saved at epoch 38 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000060 to 0.000060.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 | Train Loss: 0.000060 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.24 | SSIM: 0.9769\n",
      "--> Best model saved at epoch 39 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000060 to 0.000060.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 | Train Loss: 0.000060 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.25 | SSIM: 0.9770\n",
      "--> Best model saved at epoch 40 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000060 to 0.000060.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 | Train Loss: 0.000060 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.25 | SSIM: 0.9770\n",
      "--> Best model saved at epoch 41 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000060 to 0.000060.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 | Train Loss: 0.000060 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.25 | SSIM: 0.9770\n",
      "--> Best model saved at epoch 42 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000060 to 0.000060.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 | Train Loss: 0.000060 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.26 | SSIM: 0.9770\n",
      "--> Best model saved at epoch 43 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000060 to 0.000060.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 | Train Loss: 0.000060 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.26 | SSIM: 0.9770\n",
      "--> Best model saved at epoch 44 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000060 to 0.000060.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 | Train Loss: 0.000060 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.26 | SSIM: 0.9770\n",
      "--> Best model saved at epoch 45 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000060 to 0.000060.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 | Train Loss: 0.000060 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.26 | SSIM: 0.9770\n",
      "--> Best model saved at epoch 46 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000060 to 0.000060.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 | Train Loss: 0.000060 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.26 | SSIM: 0.9771\n",
      "--> Best model saved at epoch 47 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000060 to 0.000060.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 | Train Loss: 0.000060 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.26 | SSIM: 0.9771\n",
      "--> Best model saved at epoch 48 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000060 to 0.000060.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 | Train Loss: 0.000060 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.26 | SSIM: 0.9770\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 | Train Loss: 0.000060 | Val Loss: 0.000060 | Val MSE: 0.000060 | PSNR: 42.27 | SSIM: 0.9771\n",
      "--> Best model saved at epoch 50 with validation loss: 0.000060\n",
      "Validation loss improved from 0.000060 to 0.000060.\n",
      "Training complete. Best model saved as 'best_model.pth'.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50  # Maximum number of epochs\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "best_val_loss = float('inf')  # To track the best validation loss\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\", leave=False)\n",
    "    for batch in train_bar:\n",
    "        lr = batch['lr'].cuda()\n",
    "        hr = batch['hr'].cuda()\n",
    "        optimizer.zero_grad()\n",
    "        sr = model(lr)\n",
    "        loss = criterion(sr, hr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * lr.size(0)\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # Validation loop with progress bar\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\", leave=False)\n",
    "        for batch in val_bar:\n",
    "            lr = batch['lr'].cuda()\n",
    "            hr = batch['hr'].cuda()\n",
    "            sr = model(lr)\n",
    "            loss = criterion(sr, hr)\n",
    "            val_running_loss += loss.item() * lr.size(0)\n",
    "            val_bar.set_postfix(loss=loss.item())\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    \n",
    "    # Compute additional metrics for validation set\n",
    "    val_mse, val_psnr, val_ssim = evaluate(model, val_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | \"\n",
    "          f\"Val MSE: {val_mse:.6f} | PSNR: {val_psnr:.2f} | SSIM: {val_ssim:.4f}\")\n",
    "    \n",
    "    # Save the best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"--> Best model saved at epoch {epoch+1} with validation loss: {val_loss:.6f}\")\n",
    "    \n",
    "    # Check for early stopping\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Ending training.\")\n",
    "        break\n",
    "\n",
    "print(\"Training complete. Best model saved as 'best_model.pth'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task III.B: Transfer Learning on Real Data\n",
    "\n",
    "**Objective:**  \n",
    "Enhance low-resolution strong lensing images using a limited dataset of real HR/LR pairs collected from HSC and HST telescopes.\n",
    "\n",
    "**Dataset:**  \n",
    "- **Link:** [Task III.B](https://drive.google.com/file/d/1plYfM-jFJT7TbTMVssuCCFvLzGdxMQ4h/view?usp=sharing)\n",
    "\n",
    "\n",
    "**Implementation Steps:**\n",
    "1. **Data Loading:**  \n",
    "   - Reused the dataset class.\n",
    "2. **Transfer Learning:**  \n",
    "   - Loaded the pre-trained model from Task III.A.\n",
    "   - Fine-tuned the model on the task III.B dataset using a lower learning rate.\n",
    "3. **Training and Evaluation:**  \n",
    "   - Used early stopping to prevent overfitting.\n",
    "   - Monitored and saved the best model based on validation loss.\n",
    "   - Computed evaluation metrics (MSE, PSNR, SSIM) on the validation set.\n",
    "4. **Results:**  \n",
    "   - Compared performance with and without data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:41:45.207517Z",
     "iopub.status.busy": "2025-03-22T19:41:45.207190Z",
     "iopub.status.idle": "2025-03-22T19:41:45.211497Z",
     "shell.execute_reply": "2025-03-22T19:41:45.210537Z",
     "shell.execute_reply.started": "2025-03-22T19:41:45.207492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "task3b_hr_dir = '/kaggle/input/specific-task-3b/Dataset 3B/Dataset/HR'\n",
    "task3b_lr_dir = '/kaggle/input/specific-task-3b/Dataset 3B/Dataset/LR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:41:54.771606Z",
     "iopub.status.busy": "2025-03-22T19:41:54.771274Z",
     "iopub.status.idle": "2025-03-22T19:41:54.776656Z",
     "shell.execute_reply": "2025-03-22T19:41:54.775681Z",
     "shell.execute_reply.started": "2025-03-22T19:41:54.771576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AugmentedSuperResolutionDataset(SuperResolutionDataset):\n",
    "    def __init__(self, hr_dir, lr_dir, transform=None):\n",
    "        super().__init__(hr_dir, lr_dir, transform)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = super().__getitem__(idx)\n",
    "        # Example augmentation: Random horizontal flip (you can add more augmentations if desired)\n",
    "        if np.random.rand() > 0.5:\n",
    "            sample['lr'] = torch.flip(sample['lr'], dims=[2])\n",
    "            sample['hr'] = torch.flip(sample['hr'], dims=[2])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:42:05.531469Z",
     "iopub.status.busy": "2025-03-22T19:42:05.531157Z",
     "iopub.status.idle": "2025-03-22T19:42:05.539569Z",
     "shell.execute_reply": "2025-03-22T19:42:05.538781Z",
     "shell.execute_reply.started": "2025-03-22T19:42:05.531448Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_task3b = AugmentedSuperResolutionDataset(task3b_hr_dir, task3b_lr_dir)\n",
    "train_size = int(0.9 * len(dataset_task3b))\n",
    "val_size = len(dataset_task3b) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset_task3b, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:42:49.279878Z",
     "iopub.status.busy": "2025-03-22T19:42:49.279540Z",
     "iopub.status.idle": "2025-03-22T19:42:49.290928Z",
     "shell.execute_reply": "2025-03-22T19:42:49.290062Z",
     "shell.execute_reply.started": "2025-03-22T19:42:49.279854Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained weights loaded from Task III.A.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-6a1ac7f23a97>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_ft.load_state_dict(torch.load(pretrained_path))\n"
     ]
    }
   ],
   "source": [
    "model_ft = SuperResolutionModel(scale_factor=2).cuda()\n",
    "pretrained_path = 'best_model.pth'\n",
    "if os.path.exists(pretrained_path):\n",
    "    model_ft.load_state_dict(torch.load(pretrained_path))\n",
    "    print(\"Pre-trained weights loaded from Task III.A.\")\n",
    "else:\n",
    "    print(\"Pre-trained model not found. Please ensure 'best_model.pth' is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:43:02.621722Z",
     "iopub.status.busy": "2025-03-22T19:43:02.621421Z",
     "iopub.status.idle": "2025-03-22T19:43:02.626410Z",
     "shell.execute_reply": "2025-03-22T19:43:02.625529Z",
     "shell.execute_reply.started": "2025-03-22T19:43:02.621700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "# Use a lower learning rate for fine-tuning\n",
    "optimizer = optim.Adam(model_ft.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:45:08.100150Z",
     "iopub.status.busy": "2025-03-22T19:45:08.099777Z",
     "iopub.status.idle": "2025-03-22T19:45:52.267585Z",
     "shell.execute_reply": "2025-03-22T19:45:52.266476Z",
     "shell.execute_reply.started": "2025-03-22T19:45:08.100124Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning on Task III.B dataset...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.006301 | Val Loss: 0.003610 | Val MSE: 0.003615 | PSNR: 26.68 | SSIM: 0.5073\n",
      "--> Best model (Task III.B) saved at epoch 1 with validation loss: 0.003610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 0.002900 | Val Loss: 0.001485 | Val MSE: 0.001490 | PSNR: 30.44 | SSIM: 0.6207\n",
      "--> Best model (Task III.B) saved at epoch 2 with validation loss: 0.001485\n",
      "Validation loss improved from 0.003610 to 0.001485.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 0.001964 | Val Loss: 0.000959 | Val MSE: 0.000963 | PSNR: 31.77 | SSIM: 0.6468\n",
      "--> Best model (Task III.B) saved at epoch 3 with validation loss: 0.000959\n",
      "Validation loss improved from 0.001485 to 0.000959.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 0.001818 | Val Loss: 0.000854 | Val MSE: 0.000854 | PSNR: 32.23 | SSIM: 0.6902\n",
      "--> Best model (Task III.B) saved at epoch 4 with validation loss: 0.000854\n",
      "Validation loss improved from 0.000959 to 0.000854.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 0.001726 | Val Loss: 0.000794 | Val MSE: 0.000794 | PSNR: 32.51 | SSIM: 0.7255\n",
      "--> Best model (Task III.B) saved at epoch 5 with validation loss: 0.000794\n",
      "Validation loss improved from 0.000854 to 0.000794.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 0.001676 | Val Loss: 0.000779 | Val MSE: 0.000779 | PSNR: 32.56 | SSIM: 0.7409\n",
      "--> Best model (Task III.B) saved at epoch 6 with validation loss: 0.000779\n",
      "Validation loss improved from 0.000794 to 0.000779.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Train Loss: 0.001644 | Val Loss: 0.000752 | Val MSE: 0.000752 | PSNR: 32.63 | SSIM: 0.7521\n",
      "--> Best model (Task III.B) saved at epoch 7 with validation loss: 0.000752\n",
      "Validation loss improved from 0.000779 to 0.000752.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 0.001626 | Val Loss: 0.000733 | Val MSE: 0.000736 | PSNR: 32.66 | SSIM: 0.7583\n",
      "--> Best model (Task III.B) saved at epoch 8 with validation loss: 0.000733\n",
      "Validation loss improved from 0.000752 to 0.000733.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 0.001603 | Val Loss: 0.000718 | Val MSE: 0.000717 | PSNR: 32.74 | SSIM: 0.7642\n",
      "--> Best model (Task III.B) saved at epoch 9 with validation loss: 0.000718\n",
      "Validation loss improved from 0.000733 to 0.000718.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 0.001589 | Val Loss: 0.000719 | Val MSE: 0.000718 | PSNR: 32.74 | SSIM: 0.7650\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Train Loss: 0.001577 | Val Loss: 0.000704 | Val MSE: 0.000701 | PSNR: 32.81 | SSIM: 0.7696\n",
      "--> Best model (Task III.B) saved at epoch 11 with validation loss: 0.000704\n",
      "Validation loss improved from 0.000718 to 0.000704.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | Train Loss: 0.001577 | Val Loss: 0.000698 | Val MSE: 0.000694 | PSNR: 32.88 | SSIM: 0.7715\n",
      "--> Best model (Task III.B) saved at epoch 12 with validation loss: 0.000698\n",
      "Validation loss improved from 0.000704 to 0.000698.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | Train Loss: 0.001563 | Val Loss: 0.000676 | Val MSE: 0.000677 | PSNR: 32.91 | SSIM: 0.7762\n",
      "--> Best model (Task III.B) saved at epoch 13 with validation loss: 0.000676\n",
      "Validation loss improved from 0.000698 to 0.000676.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | Train Loss: 0.001544 | Val Loss: 0.000672 | Val MSE: 0.000670 | PSNR: 32.98 | SSIM: 0.7776\n",
      "--> Best model (Task III.B) saved at epoch 14 with validation loss: 0.000672\n",
      "Validation loss improved from 0.000676 to 0.000672.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | Train Loss: 0.001527 | Val Loss: 0.000633 | Val MSE: 0.000631 | PSNR: 33.16 | SSIM: 0.7919\n",
      "--> Best model (Task III.B) saved at epoch 15 with validation loss: 0.000633\n",
      "Validation loss improved from 0.000672 to 0.000633.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | Train Loss: 0.001519 | Val Loss: 0.000644 | Val MSE: 0.000645 | PSNR: 33.09 | SSIM: 0.7875\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | Train Loss: 0.001518 | Val Loss: 0.000600 | Val MSE: 0.000599 | PSNR: 33.33 | SSIM: 0.8036\n",
      "--> Best model (Task III.B) saved at epoch 17 with validation loss: 0.000600\n",
      "Validation loss improved from 0.000633 to 0.000600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | Train Loss: 0.001508 | Val Loss: 0.000622 | Val MSE: 0.000622 | PSNR: 33.22 | SSIM: 0.7937\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | Train Loss: 0.001492 | Val Loss: 0.000616 | Val MSE: 0.000616 | PSNR: 33.25 | SSIM: 0.7949\n",
      "Validation loss did not improve. EarlyStopping counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | Train Loss: 0.001491 | Val Loss: 0.000634 | Val MSE: 0.000632 | PSNR: 33.18 | SSIM: 0.7889\n",
      "Validation loss did not improve. EarlyStopping counter: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | Train Loss: 0.001472 | Val Loss: 0.000585 | Val MSE: 0.000588 | PSNR: 33.43 | SSIM: 0.8050\n",
      "--> Best model (Task III.B) saved at epoch 21 with validation loss: 0.000585\n",
      "Validation loss improved from 0.000600 to 0.000585.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | Train Loss: 0.001468 | Val Loss: 0.000575 | Val MSE: 0.000575 | PSNR: 33.52 | SSIM: 0.8088\n",
      "--> Best model (Task III.B) saved at epoch 22 with validation loss: 0.000575\n",
      "Validation loss improved from 0.000585 to 0.000575.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | Train Loss: 0.001461 | Val Loss: 0.000589 | Val MSE: 0.000587 | PSNR: 33.47 | SSIM: 0.8032\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | Train Loss: 0.001455 | Val Loss: 0.000571 | Val MSE: 0.000569 | PSNR: 33.59 | SSIM: 0.8094\n",
      "--> Best model (Task III.B) saved at epoch 24 with validation loss: 0.000571\n",
      "Validation loss improved from 0.000575 to 0.000571.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 | Train Loss: 0.001478 | Val Loss: 0.000605 | Val MSE: 0.000606 | PSNR: 33.32 | SSIM: 0.7951\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 | Train Loss: 0.001443 | Val Loss: 0.000564 | Val MSE: 0.000564 | PSNR: 33.59 | SSIM: 0.8097\n",
      "--> Best model (Task III.B) saved at epoch 26 with validation loss: 0.000564\n",
      "Validation loss improved from 0.000571 to 0.000564.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 | Train Loss: 0.001437 | Val Loss: 0.000548 | Val MSE: 0.000550 | PSNR: 33.72 | SSIM: 0.8156\n",
      "--> Best model (Task III.B) saved at epoch 27 with validation loss: 0.000548\n",
      "Validation loss improved from 0.000564 to 0.000548.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 | Train Loss: 0.001439 | Val Loss: 0.000523 | Val MSE: 0.000525 | PSNR: 33.86 | SSIM: 0.8252\n",
      "--> Best model (Task III.B) saved at epoch 28 with validation loss: 0.000523\n",
      "Validation loss improved from 0.000548 to 0.000523.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 | Train Loss: 0.001437 | Val Loss: 0.000541 | Val MSE: 0.000543 | PSNR: 33.72 | SSIM: 0.8177\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 | Train Loss: 0.001422 | Val Loss: 0.000545 | Val MSE: 0.000547 | PSNR: 33.70 | SSIM: 0.8146\n",
      "Validation loss did not improve. EarlyStopping counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 | Train Loss: 0.001417 | Val Loss: 0.000530 | Val MSE: 0.000528 | PSNR: 33.85 | SSIM: 0.8209\n",
      "Validation loss did not improve. EarlyStopping counter: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 | Train Loss: 0.001415 | Val Loss: 0.000544 | Val MSE: 0.000545 | PSNR: 33.73 | SSIM: 0.8149\n",
      "Validation loss did not improve. EarlyStopping counter: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 | Train Loss: 0.001411 | Val Loss: 0.000513 | Val MSE: 0.000512 | PSNR: 33.93 | SSIM: 0.8284\n",
      "--> Best model (Task III.B) saved at epoch 33 with validation loss: 0.000513\n",
      "Validation loss improved from 0.000523 to 0.000513.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 | Train Loss: 0.001410 | Val Loss: 0.000510 | Val MSE: 0.000513 | PSNR: 33.94 | SSIM: 0.8285\n",
      "--> Best model (Task III.B) saved at epoch 34 with validation loss: 0.000510\n",
      "Validation loss improved from 0.000513 to 0.000510.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 | Train Loss: 0.001402 | Val Loss: 0.000532 | Val MSE: 0.000532 | PSNR: 33.81 | SSIM: 0.8191\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 | Train Loss: 0.001402 | Val Loss: 0.000516 | Val MSE: 0.000513 | PSNR: 33.96 | SSIM: 0.8252\n",
      "Validation loss did not improve. EarlyStopping counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 | Train Loss: 0.001392 | Val Loss: 0.000531 | Val MSE: 0.000532 | PSNR: 33.81 | SSIM: 0.8185\n",
      "Validation loss did not improve. EarlyStopping counter: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 | Train Loss: 0.001388 | Val Loss: 0.000510 | Val MSE: 0.000509 | PSNR: 34.01 | SSIM: 0.8258\n",
      "Validation loss did not improve. EarlyStopping counter: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 | Train Loss: 0.001386 | Val Loss: 0.000482 | Val MSE: 0.000482 | PSNR: 34.22 | SSIM: 0.8397\n",
      "--> Best model (Task III.B) saved at epoch 39 with validation loss: 0.000482\n",
      "Validation loss improved from 0.000510 to 0.000482.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 | Train Loss: 0.001385 | Val Loss: 0.000489 | Val MSE: 0.000491 | PSNR: 34.13 | SSIM: 0.8346\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 | Train Loss: 0.001377 | Val Loss: 0.000501 | Val MSE: 0.000501 | PSNR: 34.06 | SSIM: 0.8297\n",
      "Validation loss did not improve. EarlyStopping counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 | Train Loss: 0.001374 | Val Loss: 0.000474 | Val MSE: 0.000472 | PSNR: 34.27 | SSIM: 0.8435\n",
      "--> Best model (Task III.B) saved at epoch 42 with validation loss: 0.000474\n",
      "Validation loss improved from 0.000482 to 0.000474.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 | Train Loss: 0.001374 | Val Loss: 0.000481 | Val MSE: 0.000481 | PSNR: 34.22 | SSIM: 0.8398\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 | Train Loss: 0.001370 | Val Loss: 0.000514 | Val MSE: 0.000514 | PSNR: 33.93 | SSIM: 0.8258\n",
      "Validation loss did not improve. EarlyStopping counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 | Train Loss: 0.001366 | Val Loss: 0.000477 | Val MSE: 0.000474 | PSNR: 34.24 | SSIM: 0.8413\n",
      "Validation loss did not improve. EarlyStopping counter: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 | Train Loss: 0.001368 | Val Loss: 0.000462 | Val MSE: 0.000462 | PSNR: 34.36 | SSIM: 0.8476\n",
      "--> Best model (Task III.B) saved at epoch 46 with validation loss: 0.000462\n",
      "Validation loss improved from 0.000474 to 0.000462.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 | Train Loss: 0.001356 | Val Loss: 0.000488 | Val MSE: 0.000490 | PSNR: 34.11 | SSIM: 0.8342\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 | Train Loss: 0.001358 | Val Loss: 0.000461 | Val MSE: 0.000458 | PSNR: 34.36 | SSIM: 0.8469\n",
      "--> Best model (Task III.B) saved at epoch 48 with validation loss: 0.000461\n",
      "Validation loss improved from 0.000462 to 0.000461.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 | Train Loss: 0.001361 | Val Loss: 0.000493 | Val MSE: 0.000490 | PSNR: 34.14 | SSIM: 0.8323\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 | Train Loss: 0.001355 | Val Loss: 0.000468 | Val MSE: 0.000468 | PSNR: 34.27 | SSIM: 0.8424\n",
      "Validation loss did not improve. EarlyStopping counter: 2/5\n",
      "Fine-tuning complete. Best model saved as 'best_model_task3b.pth'.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50  # maximum number of epochs for fine-tuning\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"Starting fine-tuning on Task III.B dataset...\\n\")\n",
    "for epoch in range(num_epochs):\n",
    "    model_ft.train()\n",
    "    running_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\", leave=False)\n",
    "    for batch in train_bar:\n",
    "        lr = batch['lr'].cuda()\n",
    "        hr = batch['hr'].cuda()\n",
    "        optimizer.zero_grad()\n",
    "        sr = model_ft(lr)\n",
    "        loss = criterion(sr, hr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * lr.size(0)\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # Validation loop\n",
    "    model_ft.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\", leave=False)\n",
    "        for batch in val_bar:\n",
    "            lr = batch['lr'].cuda()\n",
    "            hr = batch['hr'].cuda()\n",
    "            sr = model_ft(lr)\n",
    "            loss = criterion(sr, hr)\n",
    "            val_running_loss += loss.item() * lr.size(0)\n",
    "            val_bar.set_postfix(loss=loss.item())\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    \n",
    "    # Compute additional metrics\n",
    "    val_mse, val_psnr, val_ssim = evaluate(model_ft, val_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | \"\n",
    "          f\"Val MSE: {val_mse:.6f} | PSNR: {val_psnr:.2f} | SSIM: {val_ssim:.4f}\")\n",
    "    \n",
    "    # Save best model for Task III.B fine-tuning\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model_ft.state_dict(), 'best_model_task3b.pth')\n",
    "        print(f\"--> Best model (Task III.B) saved at epoch {epoch+1} with validation loss: {val_loss:.6f}\")\n",
    "    \n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Ending fine-tuning.\")\n",
    "        break\n",
    "\n",
    "print(\"Fine-tuning complete. Best model saved as 'best_model_task3b.pth'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task III.B: Super-Resolution on Real Data with Data Augmentation\n",
    "\n",
    "Fine tuning our pre-trained super-resolution model from Task III.A using a limited dataset of real HR/LR pairs (300 pairs). To help the model generalize better given the small dataset, I applied data augmentation (e.g., random horizontal flips) during training. I reused previously defined classes and functions (`SRCNN`, `SuperResolutionModel`, `EarlyStopping`, and `evaluate`), and only adjusted the data loading pipeline and training parameters as needed.\n",
    "\n",
    "The fine-tuning was monitored using validation metrics (MSE, PSNR, SSIM), and early stopping was used to avoid overfitting. The best model is saved for later analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:48:34.923494Z",
     "iopub.status.busy": "2025-03-22T19:48:34.923134Z",
     "iopub.status.idle": "2025-03-22T19:48:34.929146Z",
     "shell.execute_reply": "2025-03-22T19:48:34.928152Z",
     "shell.execute_reply.started": "2025-03-22T19:48:34.923468Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AugmentedSuperResolutionDataset(SuperResolutionDataset):\n",
    "    def __init__(self, hr_dir, lr_dir, transform=None):\n",
    "        super().__init__(hr_dir, lr_dir, transform)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = super().__getitem__(idx)\n",
    "        # Apply a simple data augmentation: random horizontal flip\n",
    "        if np.random.rand() > 0.5:\n",
    "            sample['lr'] = torch.flip(sample['lr'], dims=[2])\n",
    "            sample['hr'] = torch.flip(sample['hr'], dims=[2])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:48:45.151710Z",
     "iopub.status.busy": "2025-03-22T19:48:45.151386Z",
     "iopub.status.idle": "2025-03-22T19:48:45.155283Z",
     "shell.execute_reply": "2025-03-22T19:48:45.154418Z",
     "shell.execute_reply.started": "2025-03-22T19:48:45.151686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "task3b_hr_dir = '/kaggle/input/specific-task-3b/Dataset 3B/Dataset/HR'\n",
    "task3b_lr_dir = '/kaggle/input/specific-task-3b/Dataset 3B/Dataset/LR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:49:09.105565Z",
     "iopub.status.busy": "2025-03-22T19:49:09.105261Z",
     "iopub.status.idle": "2025-03-22T19:49:09.115964Z",
     "shell.execute_reply": "2025-03-22T19:49:09.115244Z",
     "shell.execute_reply.started": "2025-03-22T19:49:09.105540Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task III.B - Total samples: 300 | Train samples: 270 | Val samples: 30\n"
     ]
    }
   ],
   "source": [
    "dataset_task3b = AugmentedSuperResolutionDataset(task3b_hr_dir, task3b_lr_dir)\n",
    "train_size = int(0.9 * len(dataset_task3b))\n",
    "val_size = len(dataset_task3b) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset_task3b, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Task III.B - Total samples: {len(dataset_task3b)} | Train samples: {len(train_dataset)} | Val samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:49:21.571687Z",
     "iopub.status.busy": "2025-03-22T19:49:21.571387Z",
     "iopub.status.idle": "2025-03-22T19:49:21.583474Z",
     "shell.execute_reply": "2025-03-22T19:49:21.582579Z",
     "shell.execute_reply.started": "2025-03-22T19:49:21.571665Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained weights loaded from Task III.A.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-c3b279ca6815>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_ft.load_state_dict(torch.load(pretrained_path))\n"
     ]
    }
   ],
   "source": [
    "model_ft = SuperResolutionModel(scale_factor=2).cuda()\n",
    "pretrained_path = 'best_model.pth'\n",
    "if os.path.exists(pretrained_path):\n",
    "    model_ft.load_state_dict(torch.load(pretrained_path))\n",
    "    print(\"Pre-trained weights loaded from Task III.A.\")\n",
    "else:\n",
    "    print(\"Pre-trained model not found. Please ensure 'best_model.pth' is available.\")\n",
    "\n",
    "# Set a lower learning rate for fine-tuning\n",
    "optimizer = optim.Adam(model_ft.parameters(), lr=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Early stopping and best model saving (reuse EarlyStopping)\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "best_val_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:49:39.819467Z",
     "iopub.status.busy": "2025-03-22T19:49:39.819124Z",
     "iopub.status.idle": "2025-03-22T19:50:23.203587Z",
     "shell.execute_reply": "2025-03-22T19:50:23.202355Z",
     "shell.execute_reply.started": "2025-03-22T19:49:39.819441Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fine-tuning on Task III.B dataset...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.006198 | Val Loss: 0.003043 | Val MSE: 0.003040 | PSNR: 28.24 | SSIM: 0.6068\n",
      "--> Best model (Task III.B) saved at epoch 1 with validation loss: 0.003043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 0.002879 | Val Loss: 0.001395 | Val MSE: 0.001396 | PSNR: 30.76 | SSIM: 0.5707\n",
      "--> Best model (Task III.B) saved at epoch 2 with validation loss: 0.001395\n",
      "Validation loss improved from 0.003043 to 0.001395.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 0.001977 | Val Loss: 0.001133 | Val MSE: 0.001140 | PSNR: 31.25 | SSIM: 0.5338\n",
      "--> Best model (Task III.B) saved at epoch 3 with validation loss: 0.001133\n",
      "Validation loss improved from 0.001395 to 0.001133.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 0.001801 | Val Loss: 0.001040 | Val MSE: 0.001042 | PSNR: 31.60 | SSIM: 0.5635\n",
      "--> Best model (Task III.B) saved at epoch 4 with validation loss: 0.001040\n",
      "Validation loss improved from 0.001133 to 0.001040.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 0.001720 | Val Loss: 0.000974 | Val MSE: 0.000976 | PSNR: 31.95 | SSIM: 0.6288\n",
      "--> Best model (Task III.B) saved at epoch 5 with validation loss: 0.000974\n",
      "Validation loss improved from 0.001040 to 0.000974.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 0.001661 | Val Loss: 0.000947 | Val MSE: 0.000947 | PSNR: 32.21 | SSIM: 0.6814\n",
      "--> Best model (Task III.B) saved at epoch 6 with validation loss: 0.000947\n",
      "Validation loss improved from 0.000974 to 0.000947.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Train Loss: 0.001624 | Val Loss: 0.000930 | Val MSE: 0.000930 | PSNR: 32.24 | SSIM: 0.6981\n",
      "--> Best model (Task III.B) saved at epoch 7 with validation loss: 0.000930\n",
      "Validation loss improved from 0.000947 to 0.000930.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 0.001613 | Val Loss: 0.000917 | Val MSE: 0.000918 | PSNR: 32.36 | SSIM: 0.7285\n",
      "--> Best model (Task III.B) saved at epoch 8 with validation loss: 0.000917\n",
      "Validation loss improved from 0.000930 to 0.000917.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 0.001590 | Val Loss: 0.000908 | Val MSE: 0.000905 | PSNR: 32.42 | SSIM: 0.7467\n",
      "--> Best model (Task III.B) saved at epoch 9 with validation loss: 0.000908\n",
      "Validation loss improved from 0.000917 to 0.000908.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 0.001570 | Val Loss: 0.000894 | Val MSE: 0.000891 | PSNR: 32.53 | SSIM: 0.7610\n",
      "--> Best model (Task III.B) saved at epoch 10 with validation loss: 0.000894\n",
      "Validation loss improved from 0.000908 to 0.000894.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Train Loss: 0.001558 | Val Loss: 0.000881 | Val MSE: 0.000882 | PSNR: 32.62 | SSIM: 0.7702\n",
      "--> Best model (Task III.B) saved at epoch 11 with validation loss: 0.000881\n",
      "Validation loss improved from 0.000894 to 0.000881.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | Train Loss: 0.001550 | Val Loss: 0.000870 | Val MSE: 0.000874 | PSNR: 32.66 | SSIM: 0.7758\n",
      "--> Best model (Task III.B) saved at epoch 12 with validation loss: 0.000870\n",
      "Validation loss improved from 0.000881 to 0.000870.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | Train Loss: 0.001534 | Val Loss: 0.000859 | Val MSE: 0.000860 | PSNR: 32.73 | SSIM: 0.7810\n",
      "--> Best model (Task III.B) saved at epoch 13 with validation loss: 0.000859\n",
      "Validation loss improved from 0.000870 to 0.000859.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | Train Loss: 0.001521 | Val Loss: 0.000849 | Val MSE: 0.000847 | PSNR: 32.81 | SSIM: 0.7870\n",
      "--> Best model (Task III.B) saved at epoch 14 with validation loss: 0.000849\n",
      "Validation loss improved from 0.000859 to 0.000849.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | Train Loss: 0.001511 | Val Loss: 0.000837 | Val MSE: 0.000840 | PSNR: 32.86 | SSIM: 0.7884\n",
      "--> Best model (Task III.B) saved at epoch 15 with validation loss: 0.000837\n",
      "Validation loss improved from 0.000849 to 0.000837.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | Train Loss: 0.001496 | Val Loss: 0.000827 | Val MSE: 0.000826 | PSNR: 32.94 | SSIM: 0.7955\n",
      "--> Best model (Task III.B) saved at epoch 16 with validation loss: 0.000827\n",
      "Validation loss improved from 0.000837 to 0.000827.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | Train Loss: 0.001481 | Val Loss: 0.000820 | Val MSE: 0.000818 | PSNR: 32.95 | SSIM: 0.7898\n",
      "--> Best model (Task III.B) saved at epoch 17 with validation loss: 0.000820\n",
      "Validation loss improved from 0.000827 to 0.000820.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | Train Loss: 0.001472 | Val Loss: 0.000812 | Val MSE: 0.000811 | PSNR: 33.00 | SSIM: 0.7949\n",
      "--> Best model (Task III.B) saved at epoch 18 with validation loss: 0.000812\n",
      "Validation loss improved from 0.000820 to 0.000812.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | Train Loss: 0.001462 | Val Loss: 0.000796 | Val MSE: 0.000799 | PSNR: 33.10 | SSIM: 0.8028\n",
      "--> Best model (Task III.B) saved at epoch 19 with validation loss: 0.000796\n",
      "Validation loss improved from 0.000812 to 0.000796.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | Train Loss: 0.001454 | Val Loss: 0.000787 | Val MSE: 0.000788 | PSNR: 33.16 | SSIM: 0.8025\n",
      "--> Best model (Task III.B) saved at epoch 20 with validation loss: 0.000787\n",
      "Validation loss improved from 0.000796 to 0.000787.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | Train Loss: 0.001448 | Val Loss: 0.000783 | Val MSE: 0.000783 | PSNR: 33.17 | SSIM: 0.7987\n",
      "--> Best model (Task III.B) saved at epoch 21 with validation loss: 0.000783\n",
      "Validation loss improved from 0.000787 to 0.000783.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | Train Loss: 0.001442 | Val Loss: 0.000774 | Val MSE: 0.000773 | PSNR: 33.29 | SSIM: 0.8104\n",
      "--> Best model (Task III.B) saved at epoch 22 with validation loss: 0.000774\n",
      "Validation loss improved from 0.000783 to 0.000774.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | Train Loss: 0.001439 | Val Loss: 0.000776 | Val MSE: 0.000774 | PSNR: 33.24 | SSIM: 0.8023\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | Train Loss: 0.001420 | Val Loss: 0.000767 | Val MSE: 0.000768 | PSNR: 33.33 | SSIM: 0.8127\n",
      "--> Best model (Task III.B) saved at epoch 24 with validation loss: 0.000767\n",
      "Validation loss improved from 0.000774 to 0.000767.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 | Train Loss: 0.001414 | Val Loss: 0.000763 | Val MSE: 0.000765 | PSNR: 33.31 | SSIM: 0.8090\n",
      "--> Best model (Task III.B) saved at epoch 25 with validation loss: 0.000763\n",
      "Validation loss improved from 0.000767 to 0.000763.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 | Train Loss: 0.001415 | Val Loss: 0.000757 | Val MSE: 0.000758 | PSNR: 33.37 | SSIM: 0.8084\n",
      "--> Best model (Task III.B) saved at epoch 26 with validation loss: 0.000757\n",
      "Validation loss improved from 0.000763 to 0.000757.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 | Train Loss: 0.001402 | Val Loss: 0.000759 | Val MSE: 0.000757 | PSNR: 33.40 | SSIM: 0.8094\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 | Train Loss: 0.001398 | Val Loss: 0.000749 | Val MSE: 0.000751 | PSNR: 33.42 | SSIM: 0.8114\n",
      "--> Best model (Task III.B) saved at epoch 28 with validation loss: 0.000749\n",
      "Validation loss improved from 0.000757 to 0.000749.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 | Train Loss: 0.001395 | Val Loss: 0.000753 | Val MSE: 0.000755 | PSNR: 33.41 | SSIM: 0.8130\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 | Train Loss: 0.001387 | Val Loss: 0.000749 | Val MSE: 0.000749 | PSNR: 33.46 | SSIM: 0.8067\n",
      "--> Best model (Task III.B) saved at epoch 30 with validation loss: 0.000749\n",
      "Validation loss improved from 0.000749 to 0.000749.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 | Train Loss: 0.001386 | Val Loss: 0.000751 | Val MSE: 0.000751 | PSNR: 33.51 | SSIM: 0.8212\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 | Train Loss: 0.001384 | Val Loss: 0.000746 | Val MSE: 0.000746 | PSNR: 33.48 | SSIM: 0.8129\n",
      "--> Best model (Task III.B) saved at epoch 32 with validation loss: 0.000746\n",
      "Validation loss improved from 0.000749 to 0.000746.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 | Train Loss: 0.001391 | Val Loss: 0.000751 | Val MSE: 0.000750 | PSNR: 33.55 | SSIM: 0.8253\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 | Train Loss: 0.001383 | Val Loss: 0.000735 | Val MSE: 0.000738 | PSNR: 33.55 | SSIM: 0.8148\n",
      "--> Best model (Task III.B) saved at epoch 34 with validation loss: 0.000735\n",
      "Validation loss improved from 0.000746 to 0.000735.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 | Train Loss: 0.001368 | Val Loss: 0.000742 | Val MSE: 0.000742 | PSNR: 33.58 | SSIM: 0.8224\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 | Train Loss: 0.001371 | Val Loss: 0.000738 | Val MSE: 0.000739 | PSNR: 33.55 | SSIM: 0.8166\n",
      "Validation loss did not improve. EarlyStopping counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 | Train Loss: 0.001376 | Val Loss: 0.000735 | Val MSE: 0.000734 | PSNR: 33.56 | SSIM: 0.8095\n",
      "--> Best model (Task III.B) saved at epoch 37 with validation loss: 0.000735\n",
      "Validation loss improved from 0.000735 to 0.000735.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 | Train Loss: 0.001363 | Val Loss: 0.000734 | Val MSE: 0.000733 | PSNR: 33.61 | SSIM: 0.8198\n",
      "--> Best model (Task III.B) saved at epoch 38 with validation loss: 0.000734\n",
      "Validation loss improved from 0.000735 to 0.000734.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 | Train Loss: 0.001357 | Val Loss: 0.000726 | Val MSE: 0.000728 | PSNR: 33.65 | SSIM: 0.8216\n",
      "--> Best model (Task III.B) saved at epoch 39 with validation loss: 0.000726\n",
      "Validation loss improved from 0.000734 to 0.000726.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 | Train Loss: 0.001356 | Val Loss: 0.000730 | Val MSE: 0.000730 | PSNR: 33.55 | SSIM: 0.8089\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 | Train Loss: 0.001355 | Val Loss: 0.000725 | Val MSE: 0.000725 | PSNR: 33.71 | SSIM: 0.8272\n",
      "--> Best model (Task III.B) saved at epoch 41 with validation loss: 0.000725\n",
      "Validation loss improved from 0.000726 to 0.000725.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 | Train Loss: 0.001349 | Val Loss: 0.000719 | Val MSE: 0.000719 | PSNR: 33.74 | SSIM: 0.8255\n",
      "--> Best model (Task III.B) saved at epoch 42 with validation loss: 0.000719\n",
      "Validation loss improved from 0.000725 to 0.000719.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 | Train Loss: 0.001345 | Val Loss: 0.000719 | Val MSE: 0.000717 | PSNR: 33.75 | SSIM: 0.8245\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 | Train Loss: 0.001341 | Val Loss: 0.000717 | Val MSE: 0.000717 | PSNR: 33.74 | SSIM: 0.8246\n",
      "--> Best model (Task III.B) saved at epoch 44 with validation loss: 0.000717\n",
      "Validation loss improved from 0.000719 to 0.000717.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 | Train Loss: 0.001336 | Val Loss: 0.000712 | Val MSE: 0.000712 | PSNR: 33.82 | SSIM: 0.8324\n",
      "--> Best model (Task III.B) saved at epoch 45 with validation loss: 0.000712\n",
      "Validation loss improved from 0.000717 to 0.000712.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 | Train Loss: 0.001332 | Val Loss: 0.000712 | Val MSE: 0.000711 | PSNR: 33.78 | SSIM: 0.8225\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 | Train Loss: 0.001332 | Val Loss: 0.000711 | Val MSE: 0.000705 | PSNR: 33.88 | SSIM: 0.8307\n",
      "--> Best model (Task III.B) saved at epoch 47 with validation loss: 0.000711\n",
      "Validation loss improved from 0.000712 to 0.000711.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 | Train Loss: 0.001331 | Val Loss: 0.000708 | Val MSE: 0.000705 | PSNR: 33.86 | SSIM: 0.8264\n",
      "--> Best model (Task III.B) saved at epoch 48 with validation loss: 0.000708\n",
      "Validation loss improved from 0.000711 to 0.000708.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 | Train Loss: 0.001330 | Val Loss: 0.000710 | Val MSE: 0.000705 | PSNR: 33.84 | SSIM: 0.8235\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 | Train Loss: 0.001323 | Val Loss: 0.000707 | Val MSE: 0.000708 | PSNR: 33.85 | SSIM: 0.8267\n",
      "--> Best model (Task III.B) saved at epoch 50 with validation loss: 0.000707\n",
      "Validation loss improved from 0.000708 to 0.000707.\n",
      "Fine-tuning complete. Best model saved as 'best_model_task3b.pth'.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50  # Maximum epochs for fine-tuning\n",
    "print(\"Starting fine-tuning on Task III.B dataset...\\n\")\n",
    "for epoch in range(num_epochs):\n",
    "    model_ft.train()\n",
    "    running_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\", leave=False)\n",
    "    for batch in train_bar:\n",
    "        lr = batch['lr'].cuda()\n",
    "        hr = batch['hr'].cuda()\n",
    "        optimizer.zero_grad()\n",
    "        sr = model_ft(lr)\n",
    "        loss = criterion(sr, hr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * lr.size(0)\n",
    "        train_bar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # Validation loop\n",
    "    model_ft.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\", leave=False)\n",
    "        for batch in val_bar:\n",
    "            lr = batch['lr'].cuda()\n",
    "            hr = batch['hr'].cuda()\n",
    "            sr = model_ft(lr)\n",
    "            loss = criterion(sr, hr)\n",
    "            val_running_loss += loss.item() * lr.size(0)\n",
    "            val_bar.set_postfix(loss=loss.item())\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    \n",
    "    # Compute additional metrics on the validation set\n",
    "    val_mse, val_psnr, val_ssim = evaluate(model_ft, val_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | \"\n",
    "          f\"Val MSE: {val_mse:.6f} | PSNR: {val_psnr:.2f} | SSIM: {val_ssim:.4f}\")\n",
    "    \n",
    "    # Save the best model for Task III.B\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model_ft.state_dict(), 'best_model_task3b.pth')\n",
    "        print(f\"--> Best model (Task III.B) saved at epoch {epoch+1} with validation loss: {val_loss:.6f}\")\n",
    "    \n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Ending fine-tuning.\")\n",
    "        break\n",
    "\n",
    "print(\"Fine-tuning complete. Best model saved as 'best_model_task3b.pth'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCAN Experiment \n",
    "\n",
    "**Objective:**  \n",
    "Experiment with an alternative architecture, the Residual Channel Attention Network (RCAN), to see if it outperforms the baseline model.\n",
    "\n",
    "**Implementation Steps:**\n",
    "1. **Model Definition:**  \n",
    "   - Implement the RCAN architecture including:\n",
    "     - Channel Attention (CA) modules.\n",
    "     - Residual Channel Attention Blocks (RCAB).\n",
    "     - Residual Groups.\n",
    "2. **Training:**  \n",
    "   - Train RCAN using the same dataset and training utilities as before.\n",
    "   - Compare the evaluation metrics (MSE, PSNR, SSIM) to assess performance.\n",
    "3. **Analysis:**  \n",
    "   - Present the results and discuss the benefits or drawbacks compared to the baseline model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:58:23.229716Z",
     "iopub.status.busy": "2025-03-22T19:58:23.229326Z",
     "iopub.status.idle": "2025-03-22T19:58:23.235397Z",
     "shell.execute_reply": "2025-03-22T19:58:23.234591Z",
     "shell.execute_reply.started": "2025-03-22T19:58:23.229686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CALayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(CALayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv_du = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel // reduction, 1, padding=0, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channel // reduction, channel, 1, padding=0, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = self.conv_du(y)\n",
    "        return x * y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:58:32.642690Z",
     "iopub.status.busy": "2025-03-22T19:58:32.642374Z",
     "iopub.status.idle": "2025-03-22T19:58:32.648064Z",
     "shell.execute_reply": "2025-03-22T19:58:32.647198Z",
     "shell.execute_reply.started": "2025-03-22T19:58:32.642666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RCAB(nn.Module):\n",
    "    def __init__(self, channel, kernel_size=3, reduction=16, bias=True, activation=nn.ReLU(True)):\n",
    "        super(RCAB, self).__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, channel, kernel_size, padding=kernel_size//2, bias=bias),\n",
    "            activation,\n",
    "            nn.Conv2d(channel, channel, kernel_size, padding=kernel_size//2, bias=bias),\n",
    "            CALayer(channel, reduction)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:58:42.710471Z",
     "iopub.status.busy": "2025-03-22T19:58:42.710063Z",
     "iopub.status.idle": "2025-03-22T19:58:42.715464Z",
     "shell.execute_reply": "2025-03-22T19:58:42.714680Z",
     "shell.execute_reply.started": "2025-03-22T19:58:42.710433Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResidualGroup(nn.Module):\n",
    "    def __init__(self, channel, n_RCAB, kernel_size=3, reduction=16, bias=True, activation=nn.ReLU(True)):\n",
    "        super(ResidualGroup, self).__init__()\n",
    "        modules_body = [RCAB(channel, kernel_size, reduction, bias, activation) for _ in range(n_RCAB)]\n",
    "        modules_body.append(nn.Conv2d(channel, channel, kernel_size, padding=kernel_size//2, bias=bias))\n",
    "        self.body = nn.Sequential(*modules_body)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = self.body(x)\n",
    "        return res + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:58:57.388254Z",
     "iopub.status.busy": "2025-03-22T19:58:57.387830Z",
     "iopub.status.idle": "2025-03-22T19:58:57.397194Z",
     "shell.execute_reply": "2025-03-22T19:58:57.396211Z",
     "shell.execute_reply.started": "2025-03-22T19:58:57.388219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RCAN(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1, num_features=64, num_rg=5, num_rcab=10, scale=2):\n",
    "        super(RCAN, self).__init__()\n",
    "        # Shallow feature extraction\n",
    "        self.conv1 = nn.Conv2d(in_channels, num_features, kernel_size=3, padding=1, bias=True)\n",
    "        \n",
    "        # Residual Groups\n",
    "        self.residual_groups = nn.Sequential(\n",
    "            *[ResidualGroup(num_features, num_rcab, kernel_size=3, reduction=16) for _ in range(num_rg)]\n",
    "        )\n",
    "        \n",
    "        # Reconstruction\n",
    "        self.conv2 = nn.Conv2d(num_features, num_features, kernel_size=3, padding=1, bias=True)\n",
    "        # Upscaling layers\n",
    "        self.upscale = nn.Sequential(\n",
    "            nn.Conv2d(num_features, num_features * (scale ** 2), kernel_size=3, padding=1, bias=True),\n",
    "            nn.PixelShuffle(scale),\n",
    "            nn.Conv2d(num_features, out_channels, kernel_size=3, padding=1, bias=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Shallow feature extraction\n",
    "        x = self.conv1(x)\n",
    "        # Deep feature extraction through residual groups\n",
    "        x = self.residual_groups(x)\n",
    "        x = self.conv2(x)\n",
    "        # Upscale to high resolution\n",
    "        out = self.upscale(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:59:05.355424Z",
     "iopub.status.busy": "2025-03-22T19:59:05.354998Z",
     "iopub.status.idle": "2025-03-22T19:59:05.458214Z",
     "shell.execute_reply": "2025-03-22T19:59:05.457205Z",
     "shell.execute_reply.started": "2025-03-22T19:59:05.355392Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCAN(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (residual_groups): Sequential(\n",
      "    (0): ResidualGroup(\n",
      "      (body): Sequential(\n",
      "        (0): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualGroup(\n",
      "      (body): Sequential(\n",
      "        (0): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualGroup(\n",
      "      (body): Sequential(\n",
      "        (0): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualGroup(\n",
      "      (body): Sequential(\n",
      "        (0): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualGroup(\n",
      "      (body): Sequential(\n",
      "        (0): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (6): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (7): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (8): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (9): RCAB(\n",
      "          (body): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (3): CALayer(\n",
      "              (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "              (conv_du): Sequential(\n",
      "                (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "                (3): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (upscale): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): PixelShuffle(upscale_factor=2)\n",
      "    (2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_rcan = RCAN(in_channels=1, out_channels=1, num_features=64, num_rg=5, num_rcab=10, scale=2).cuda()\n",
    "print(model_rcan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:59:16.161768Z",
     "iopub.status.busy": "2025-03-22T19:59:16.161446Z",
     "iopub.status.idle": "2025-03-22T19:59:16.167936Z",
     "shell.execute_reply": "2025-03-22T19:59:16.167073Z",
     "shell.execute_reply.started": "2025-03-22T19:59:16.161743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer_rcan = torch.optim.Adam(model_rcan.parameters(), lr=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "early_stopping_rcan = EarlyStopping(patience=5, verbose=True)\n",
    "best_val_loss_rcan = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T19:59:31.745617Z",
     "iopub.status.busy": "2025-03-22T19:59:31.745285Z",
     "iopub.status.idle": "2025-03-22T20:00:41.958492Z",
     "shell.execute_reply": "2025-03-22T20:00:41.957558Z",
     "shell.execute_reply.started": "2025-03-22T19:59:31.745591Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RCAN training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.22it/s]\n",
      "Epoch 1/50 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 17.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.002670 | Val Loss: 0.001109 | Val MSE: 0.001110 | PSNR: 30.84 | SSIM: 0.7139\n",
      "--> Best RCAN model saved at epoch 1 with validation loss: 0.001109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.46it/s]\n",
      "Epoch 2/50 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 0.001531 | Val Loss: 0.001081 | Val MSE: 0.001080 | PSNR: 32.26 | SSIM: 0.8262\n",
      "--> Best RCAN model saved at epoch 2 with validation loss: 0.001081\n",
      "Validation loss improved from 0.001109 to 0.001081.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.45it/s]\n",
      "Epoch 3/50 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 16.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 0.001574 | Val Loss: 0.001036 | Val MSE: 0.001031 | PSNR: 32.49 | SSIM: 0.8104\n",
      "--> Best RCAN model saved at epoch 3 with validation loss: 0.001036\n",
      "Validation loss improved from 0.001081 to 0.001036.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.26it/s]\n",
      "Epoch 4/50 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 17.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 0.001510 | Val Loss: 0.000792 | Val MSE: 0.000794 | PSNR: 32.66 | SSIM: 0.8316\n",
      "--> Best RCAN model saved at epoch 4 with validation loss: 0.000792\n",
      "Validation loss improved from 0.001036 to 0.000792.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.47it/s]\n",
      "Epoch 5/50 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 17.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 0.001465 | Val Loss: 0.000816 | Val MSE: 0.000818 | PSNR: 33.52 | SSIM: 0.7882\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.48it/s]\n",
      "Epoch 6/50 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 18.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 0.001367 | Val Loss: 0.000870 | Val MSE: 0.000868 | PSNR: 32.87 | SSIM: 0.7740\n",
      "Validation loss did not improve. EarlyStopping counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.46it/s]\n",
      "Epoch 7/50 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Train Loss: 0.001302 | Val Loss: 0.000743 | Val MSE: 0.000743 | PSNR: 34.20 | SSIM: 0.8478\n",
      "--> Best RCAN model saved at epoch 7 with validation loss: 0.000743\n",
      "Validation loss improved from 0.000792 to 0.000743.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.44it/s]\n",
      "Epoch 8/50 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 0.001264 | Val Loss: 0.000777 | Val MSE: 0.000761 | PSNR: 33.29 | SSIM: 0.8242\n",
      "Validation loss did not improve. EarlyStopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.44it/s]\n",
      "Epoch 9/50 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 0.001303 | Val Loss: 0.000834 | Val MSE: 0.000827 | PSNR: 32.93 | SSIM: 0.7566\n",
      "Validation loss did not improve. EarlyStopping counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.43it/s]\n",
      "Epoch 10/50 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 16.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 0.001291 | Val Loss: 0.000859 | Val MSE: 0.000854 | PSNR: 34.14 | SSIM: 0.8240\n",
      "Validation loss did not improve. EarlyStopping counter: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.42it/s]\n",
      "Epoch 11/50 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 16.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Train Loss: 0.001268 | Val Loss: 0.000743 | Val MSE: 0.000744 | PSNR: 33.50 | SSIM: 0.7853\n",
      "Validation loss did not improve. EarlyStopping counter: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 [Training]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [00:05<00:00,  6.44it/s]\n",
      "Epoch 12/50 [Validation]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 18.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | Train Loss: 0.001234 | Val Loss: 0.000748 | Val MSE: 0.000759 | PSNR: 34.39 | SSIM: 0.8452\n",
      "Validation loss did not improve. EarlyStopping counter: 5/5\n",
      "Early stopping triggered for RCAN. Ending training.\n",
      "RCAN training complete. Best model saved as 'best_model_rcan.pth'.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "print(\"Starting RCAN training...\\n\")\n",
    "for epoch in range(num_epochs):\n",
    "    model_rcan.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\"):\n",
    "        lr = batch['lr'].cuda()\n",
    "        hr = batch['hr'].cuda()\n",
    "        optimizer_rcan.zero_grad()\n",
    "        sr = model_rcan(lr)\n",
    "        loss = criterion(sr, hr)\n",
    "        loss.backward()\n",
    "        optimizer_rcan.step()\n",
    "        running_loss += loss.item() * lr.size(0)\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # Validation\n",
    "    model_rcan.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Validation]\"):\n",
    "            lr = batch['lr'].cuda()\n",
    "            hr = batch['hr'].cuda()\n",
    "            sr = model_rcan(lr)\n",
    "            loss = criterion(sr, hr)\n",
    "            val_running_loss += loss.item() * lr.size(0)\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    \n",
    "    val_mse, val_psnr, val_ssim = evaluate(model_rcan, val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | \"\n",
    "          f\"Val MSE: {val_mse:.6f} | PSNR: {val_psnr:.2f} | SSIM: {val_ssim:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss_rcan:\n",
    "        best_val_loss_rcan = val_loss\n",
    "        torch.save(model_rcan.state_dict(), 'best_model_rcan.pth')\n",
    "        print(f\"--> Best RCAN model saved at epoch {epoch+1} with validation loss: {val_loss:.6f}\")\n",
    "    \n",
    "    early_stopping_rcan(val_loss)\n",
    "    if early_stopping_rcan.early_stop:\n",
    "        print(\"Early stopping triggered for RCAN. Ending training.\")\n",
    "        break\n",
    "\n",
    "print(\"RCAN training complete. Best model saved as 'best_model_rcan.pth'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this task, we developed and evaluated deep learning-based super-resolution methods for strong lensing images.\n",
    "\n",
    "### Task III.A: Super-Resolution on Simulated Data\n",
    "- **Approach:**  \n",
    "  Implementation baseline SRCNN model that first upsamples low-resolution images using bilinear interpolation and then refines them with convolutional layers.\n",
    "- **Results:**  \n",
    "  - **Validation MSE:** ~0.000060  \n",
    "  - **PSNR:** ~42.27 dB  \n",
    "  - **SSIM:** ~0.9771  \n",
    "These metrics indicate excellent reconstruction quality on simulated data, demonstrating that the model effectively captures the key features of strong lensing images.\n",
    "\n",
    "### Task III.B: Transfer Learning on Real Data\n",
    "- **Approach:**  \n",
    "  Utilised pre-trained SRCNN-based model to a limited dataset of real HR/LR pairs (300 images) using transfer learning. The model was fine-tuned with a lower learning rate and evaluated using a 90:10 trainâ€“validation split.\n",
    "- **Results without Data Augmentation:**  \n",
    "  - **Best Validation Loss:** ~0.000461 (achieved at epoch 48)  \n",
    "  - **Validation MSE:** ~0.000458  \n",
    "  - **PSNR:** ~34.36 dB  \n",
    "  - **SSIM:** ~0.8469  \n",
    "These results show that the model, when fine-tuned on real data, achieves significant improvements in image resolution. Although the performance is lower than on simulated data, it still demonstrates robust super-resolution capability.\n",
    "\n",
    "### RCAN Experiment (Alternative Approach)\n",
    "- **Approach:**  \n",
    "  I also experimented with a Residual Channel Attention Network (RCAN) to assess whether an alternative architecture could further improve performance. RCAN leverages channel attention mechanisms to emphasize important features.\n",
    "- **Results:**  \n",
    "  - **Early Best Model (Epoch 7):**  \n",
    "    - **Validation Loss:** ~0.000743  \n",
    "    - **PSNR:** ~34.20 dB  \n",
    "    - **SSIM:** ~0.8478  \n",
    "While the RCAN model performed competitively, the differences compared to the SRCNN-based approach were subtle given the limited size of the real dataset.\n",
    "\n",
    "### Final Remarks\n",
    "- **Transfer Learning Effectiveness:**  \n",
    "  The strategy of pre-training on simulated data and then fine-tuning on real data proved effective. The SRCNN-based model achieved excellent results on simulated data and robust performance on real data.\n",
    "- **Architectural Comparison:**  \n",
    "  Both the SRCNN-based model and the RCAN approach demonstrated strong performance on the real dataset. Although RCAN introduced additional complexity, its results were comparable to the baseline model.\n",
    "- **Future Work:**  \n",
    "  Future work could explore more extensive hyperparameter tuning, additional data augmentation strategies, or hybrid architectures that combine the strengths of both approaches to further enhance super-resolution quality.\n",
    "\n",
    "Overall, the quantitative metrics (MSE, PSNR, and SSIM) confirm that these deep learning-based super-resolution techniques are effective in enhancing strong lensing images, fulfilling the task requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
